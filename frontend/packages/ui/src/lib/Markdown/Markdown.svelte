<!--
 The primary prupose of this component is to render the responses generated by the LLM inside intric.
 In order to achieve this, we use the marked lexer and generate a token list from the LLM's response.
 The tokens are then mapped to components and rendered. There are some performance considerations:
 The way the current setup works (Svelte 4), we replace the whole markdown source everytime the server
 sends a new token. Additionally, everytime an new message is added to the chat, we replace the whole chat
 history with a new messages array that includes the latest message. All of these updates will trigger
 a full run of the lexer and after that a re-creation of the <RenderToken> chain. As the output is the same
 in the end, this should not trigger any DOM updates; but with very long chats or more complex components
 this migh reach some performance limitations on the JS side eventually.
 -->

<script lang="ts">
  import { intricMarkdownLexer } from "./index.js";
  import RenderToken from "./renderers/RenderToken.svelte";
  import { initReferenceContext } from "./ReferenceContext.js";
  import type { CustomRenderers } from "./CustomComponents.js";
  import type { InfoBlob } from "@intric/intric-js";
  import type { ClassValue } from "svelte/elements";

  type Props = {
    source: string;
    references?: InfoBlob[];
    customRenderers?: CustomRenderers;
    showTokenOutput?: boolean;
    class?: ClassValue;
  };

  let {
    source,
    customRenderers = {},
    showTokenOutput = false,
    references = [],
    class: cls
  }: Props = $props();

  const lexer = intricMarkdownLexer();

  initReferenceContext({
    references: () => references,
    renderer: customRenderers.inref
  });

  const tokens = $derived(lexer.lex(source));
</script>

<div class={["prose text-lg break-words", cls]}>
  {#each tokens as token (token)}
    <RenderToken {token}></RenderToken>
  {/each}
</div>

{#if showTokenOutput}
  <pre>{JSON.stringify(tokens, undefined, 2)}</pre>
{/if}
